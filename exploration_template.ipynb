{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Kickstarter Project Data\n",
    "## by Michael Mosin\n",
    "\n",
    "## Preliminary Wrangling\n",
    "\n",
    "This document explores a dataset comprised of various attributes for an assortment of 3786 Kickstarter projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages and set plots to be embedded inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "# Dataset downloaded from CSV link under \"2019-05-16\" on site: https://webrobots.io/kickstarter-datasets/\n",
    "df = pd.read_csv('Kickstarter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding ability to view all dataframe columns\n",
    "# as per https://stackoverflow.com/questions/49188960/how-to-show-all-of-columns-name-on-pandas-dataframe/49189503\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy of main dataframe so as to keep original data intact.\n",
    "df_copy = df.copy()\n",
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking Data Quality and Tidiness Issues:\n",
    "\n",
    "### Quality:\n",
    "\n",
    "- Variables \"created_at\", \"deadline\", \"launched_at\", and \"state_changed_at\" are set in unix time instead of readable datetime\n",
    "- Variables with financial values such as \"converted_pledged_amount\", \"goal\", \"pledged\", and \"usd_pledged\" are set to different decimal places, and should be rounded to at most two decimal places\n",
    "- Variables \"friends\", \"is_backing\", \"is_starred\", and \"permissions\" only have one entry and should be dropped\n",
    "- Only two entries are missing data for \"location\" (not a big deal, given that we have \"country\" data; these)\n",
    "- Only eleven entries are missing data for \"usd_type\" (this variable is not important to the investigation)\n",
    "\n",
    "### Tidiness:\n",
    "\n",
    "- Data entries in the columns \"category\", \"creator\", \"location\", \"photo\", \"profile\", and \"urls\" contain multiple pieces of information. If separated, they could be their own dataframes or made into additional columns in the main dataframe.\n",
    "    - The \"category\" variable can garner category and sub-category info for the projects\n",
    "    - The \"location\" variable can garner data regarding the project's state name, city name, and city type\n",
    "    - The \"creator\",\"photo\", \"profile\", \"urls\" variables have no data that is relevant to this project and should be dropped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Data Quality and Tidiness Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality: \n",
    "\n",
    "#### Remove (essentially) empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove variables that only have one entry.\n",
    "df_copy = df_copy.drop(columns = [\"friends\", \"is_backing\", \"is_starred\", \"permissions\"])\n",
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix time categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting unix time to readable date-time\n",
    "# as per https://stackoverflow.com/questions/19231871/convert-unix-time-to-readable-date-in-pandas-dataframe\n",
    "date_cols = [\"created_at\", \"deadline\", \"launched_at\", \"state_changed_at\"]\n",
    "for i in date_cols:\n",
    "    df_copy[i] = pd.to_datetime(df_copy[i],unit='s')\n",
    "\n",
    "df_copy[date_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[date_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix financial categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round financial values to at most two decimal places\n",
    "money_cols = [\"converted_pledged_amount\", \"goal\", \"pledged\", \"usd_pledged\"]\n",
    "for i in money_cols:\n",
    "    df_copy = df_copy.round(2)\n",
    "\n",
    "df_copy[money_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness: \n",
    "\n",
    "#### Feature Engineering - address tidiness issue of \"category\" variable by creating variables holding extracted values for main category and sub-category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View full of string entries for \"category\" variable to gauge the complexity of category strings:\n",
    "df_copy['category'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['category'][798]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract product categories and sub-catgories from strings in \"category\" variable into their own columns in dataframe\n",
    "# (Used regular expression)\n",
    "\n",
    "import re  \n",
    "\n",
    "df_copy['main_cat'] = ''\n",
    "df_copy['sub_cat'] = ''\n",
    "\n",
    "for i in np.arange(df_copy.shape[0]):\n",
    "    match = re.findall('(([- &\\'\\\\\\\\]|\\w+)+)', df_copy['category'][i])\n",
    "    df_copy['main_cat'][i] = match[5][0].title()\n",
    "    df_copy['sub_cat'][i] = match[3][0].replace('\\\\','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[['name','main_cat', 'sub_cat', 'category']].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.main_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.sub_cat.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering - address tidiness issue of \"location\" variable by creating variables holding extracted values for state, city, and type of city:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[df_copy.location.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View full string entry for \"location\" variable of third row entry to gauge the complexity of location strings:\n",
    "df_copy['location'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract product (country) states, cities, and city types from strings in \"location\" variable into their own columns in dataframe\n",
    "# (Used regular expression)\n",
    "\n",
    "df_copy['location_state'] = ''\n",
    "df_copy['location_city'] = ''\n",
    "df_copy['location_type'] = ''\n",
    "\n",
    "for i in np.arange(df_copy.shape[0]):\n",
    "    if pd.notna(df_copy.location[i]) == True:\n",
    "        match = re.findall('((?:[^\"]\\w+)+)', df_copy['location'][i])\n",
    "        df_copy['location_state'][i] = match[17]\n",
    "        df_copy['location_city'][i] = match[3]\n",
    "        df_copy['location_type'][i] = match[19]\n",
    "    else:\n",
    "        df_copy['location_state'][i] = 'NaN'\n",
    "        df_copy['location_city'][i] = 'NaN'\n",
    "        df_copy['location_type'][i] = 'NaN'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[['name', 'country', 'location_state', 'location_city', 'location_type', 'location']][1930:1933]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the structure of your dataset?\n",
    "\n",
    "There are 3786 Kickstarter projects in this dataset, with a total of 37 features, some of which are untidy, and some of which are not of interest for my exploration. I have engineered a few categorical features (related to project ctegories and location) which may come to be useful for exploration. \n",
    "\n",
    "\n",
    "### What is/are the main feature(s) of interest in your dataset?\n",
    "\n",
    "I am interested in finding out which project qualities correlate with different types of project outcomes (or, the final \"state\" of the project). \n",
    "\n",
    "\n",
    "### What features in the dataset do you think will help support your investigation into your feature(s) of interest?\n",
    "\n",
    "I believe the following features could illuminate patterns in project outcomes:\n",
    "- Number of backers\n",
    "- Length of time project was open\n",
    "- Total money pledged (relative to funding goal)\n",
    "- Project category\n",
    "- Project location (country, city type)\n",
    "- If project had \"spotlight\"\n",
    "- If project was \"staff pick\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save wrangled dataframe to new CSV file to make future manipulating easier\n",
    "df_copy.to_csv('data_wrangled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlining Wrangled Dataset \n",
    "\n",
    "### Removing extra variables, and engineering other potentially relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages and set plots to be embedded inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import wrangled dataset\n",
    "df = pd.read_csv('data_wrangled.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary variables\n",
    "df.drop(columns = ['category',\n",
    "                   'converted_pledged_amount',\n",
    "                   'creator',\n",
    "                   'currency_symbol',\n",
    "                   'currency_trailing_code',\n",
    "                   'current_currency',\n",
    "                   'disable_communication',\n",
    "                   'fx_rate',\n",
    "                   'location',\n",
    "                   'photo',\n",
    "                   'profile',\n",
    "                   'slug',\n",
    "                   'source_url',\n",
    "                   'static_usd_rate',\n",
    "                   'urls',\n",
    "                   'usd_type'],\n",
    "       inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineering features related to the time variables:\n",
    "\n",
    "- created_at\n",
    "- launched_at\n",
    "- deadline\n",
    "- state_changed_at\n",
    "\n",
    "Reference:\n",
    "\n",
    "http://www.datasciencemadesimple.com/difference-two-timestamps-seconds-minutes-hours-pandas-python-2/\n",
    "https://docs.scipy.org/doc/numpy/reference/arrays.datetime.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that time variables are of 'datetime64' type:\n",
    "date_cols = [\"created_at\", \"deadline\", \"launched_at\", \"state_changed_at\"]\n",
    "for i in date_cols:\n",
    "    df[i] = pd.to_datetime(df[i])\n",
    "\n",
    "df[date_cols].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of days it took to launch project: 'days_to_launch'\n",
    "# (days between project creation and project launch: 'launched_at' - 'created_at')\n",
    "\n",
    "df['days_to_launch'] = df['launched_at'] - df['created_at']\n",
    "df['days_to_launch']=df['days_to_launch']/np.timedelta64(1,'D')\n",
    "df.days_to_launch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of days given for project to succeed: 'days_to_succeed'\n",
    "# (days between project launch and project deadline: 'deadline' - 'launched_at')\n",
    "\n",
    "df['days_to_succeed'] = df['deadline'] - df['launched_at']\n",
    "df['days_to_succeed']=df['days_to_succeed']/np.timedelta64(1,'D')\n",
    "df.days_to_succeed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of days project was active (or reached its final 'state') : 'days_active'\n",
    "# (days between project launch and project deadline: 'state_changed_at' - 'launched_at')\n",
    "\n",
    "df['days_active'] = df['state_changed_at'] - df['launched_at']\n",
    "df['days_active']=df['days_active']/np.timedelta64(1,'D')\n",
    "df.days_active.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm whether final 'state' occurred before or after 'deadline': 'ended_early'\n",
    "# Faster code instead of for loops as per reference:\n",
    "# https://stackoverflow.com/questions/27041724/using-conditional-to-generate-new-column-in-pandas-dataframe)\n",
    "\n",
    "df['ended_early'] = np.where(df.days_active < df.days_to_succeed, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['days_to_succeed','days_active','ended_early']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineering Feature: proportion of project funding relative to goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding ratio of confirmed funds relative to funding goals: 'funded_prop'\n",
    "# ('pledged' / 'goal')\n",
    "\n",
    "df['funded_prop'] = df['pledged'] / df['goal']\n",
    "df.funded_prop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save cleaner dataframe to new CSV file to make future manipulating easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_cleaner.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Exploration\n",
    "\n",
    "> In this section, investigate distributions of individual variables. If\n",
    "you see unusual points or outliers, take a deeper look to clean things up\n",
    "and prepare yourself to look at relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages and set plots to be embedded inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import wrangled dataset\n",
    "df = pd.read_csv('data_cleaner.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set color for charts:\n",
    "base_color = sb.color_palette()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the distribution of project campaign 'states'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(data = df, x = 'state', color = base_color);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like more projects succeeded than not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the proportion of campaigns that ended early?\n",
    "Plot 'ended_early' counts with proportion percentages over bars\n",
    "\n",
    "Reference: https://stackoverflow.com/questions/31749448/how-to-add-percentages-on-top-of-bars-in-seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the plot\n",
    "ax = sb.countplot(data = df, x = 'ended_early', color = base_color)\n",
    "\n",
    "# add annotations\n",
    "n_points = df.shape[0]\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 25,\n",
    "            '{:0.1f}%'.format(100*height/n_points),\n",
    "            ha = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot 'ended_early' counts with proportion percentages over bars WHILE excluding 'live' projects - since they are still in progress and are skewing the chart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate sub-dataset which excludes projects that are 'live':\n",
    "df_notlive = df[df['state']!='live']\n",
    "df_notlive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the plot\n",
    "ax = sb.countplot(data = df_notlive, x = 'ended_early', color = base_color)\n",
    "\n",
    "# add annotations\n",
    "n_points = df_notlive.shape[0]\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 25,\n",
    "            '{:0.1f}%'.format(100*height/n_points),\n",
    "            ha = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A follow-up bivariate exploration would be to see whether the different campaign 'states' have a split within them regarding if they ended early."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the distribution of the number of backers per project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binsize = 50\n",
    "bins = np.arange(0, df_notlive['backers_count'].max()+binsize, binsize)\n",
    "\n",
    "plt.figure(figsize=[8, 5])\n",
    "plt.hist(data = df_notlive, x = 'backers_count', bins = bins)\n",
    "plt.xlabel('Number of Backers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like there is a VERY wide distribution of backers, skewed by many projects having zero or few backers, and a few outliers projects with thousands of backers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot countplot that illustrates how many projects have fewer than 10 backers:\n",
    "\n",
    "plt.figure(figsize=[8, 5])\n",
    "ax = sb.countplot(data = df_notlive, x = 'backers_count', color = base_color)\n",
    "plt.xlabel('Number of Backers')\n",
    "plt.ylabel('Number of Projects')\n",
    "plt.xlim(-0.5,9.5)\n",
    "plt.ylim(0,350)\n",
    "\n",
    "# add annotations\n",
    "for p in ax.patches[0:10]:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:.0f}'.format(height),\n",
    "            ha = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since there's a long tail in the distribution, for backer numbers of 10 or greater we plot a histplot with a log transformation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_binsize = 0.05\n",
    "bins = 10 ** np.arange(1, np.log10(df_notlive['backers_count'].max())+log_binsize, log_binsize)\n",
    "\n",
    "plt.figure(figsize=[8, 5])\n",
    "plt.hist(data = df_notlive, x = 'backers_count', bins = bins)\n",
    "plt.xscale('log')\n",
    "plt.xticks([10, 25, 50, 100, 300, 1e3, 2e3, 5e3, 1e4, 2e4, 4e4], [10, 25, 50, 100, 300, '1k', '2k', '5k', '10k', '20k', '40k'])\n",
    "plt.xlabel('Number of Backers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There still appears to be a long tail, but at least it is a little more constrained under the log transformation.\n",
    "\n",
    "#### A follow-up bivariate exploration would be to compare the number of backers relative to successful and unsuccessful projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the distribution of location type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(data = df_notlive, y = 'location_type', color = base_color);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like I extracted that information incorrectly. However, even if I had, it's almost useless given the fairly little diversity in distribution of the location type, with the vast majority of projects being in towns. At least we've learned that much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the distribution of location country?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(data = df_notlive, y = 'country', color = base_color, order = df_notlive.country.value_counts().index);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The vast majority of project campaigns are based in the US, followed by other English-speaking countries. There is some visible representation from Northern Europe, Mexico, Western Europe, and Hong Kong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the distribution of proportion of funding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notlive.funded_prop.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.boxplot(data = df_notlive, x = 'funded_prop', color = base_color);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notlive[df_notlive.funded_prop == 27588.23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like there is one data entry (index # 661) which needs to be dropped: the project's funding proportion was severly greater than that of any other, a result of the dataset stating that the campaign funding goal was ONE DOLLAR. This data entry also skews the proportion of successful projects, given that it appears to have met its (unrealistic goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notlive = df_notlive.drop([661])\n",
    "df_notlive[df_notlive.funded_prop == 27588.23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.boxplot(data = df_notlive, x = 'funded_prop', color = base_color);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binsize = 0.1\n",
    "bins = np.arange(0, 5+binsize, binsize)\n",
    "\n",
    "plt.figure(figsize=[8, 5])\n",
    "plt.hist(data = df_notlive, x = 'funded_prop', bins = bins)\n",
    "plt.xlabel('Final Funding as Proportion of Goal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_binsize = 0.01\n",
    "bins = 10 ** np.arange(-3, np.log10(df_notlive['funded_prop'].max())+log_binsize, log_binsize)\n",
    "\n",
    "plt.figure(figsize=[15, 5])\n",
    "plt.hist(data = df_notlive, x = 'funded_prop', bins = bins)\n",
    "plt.xscale('log')\n",
    "plt.xticks([.001, .003, .01, .03, .1, .3, 1, 3, 10, 25, 50, 100, 200, 400], [.001, .003, .01, .03, .1, .3, 1, 3, 10, 25, 50, 100, 200, 400])\n",
    "plt.xlabel('Final Funding as Proportion of Goal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Make sure that, after every plot or related series of plots, that you\n",
    "include a Markdown cell with comments about what you observed, and what\n",
    "you plan on investigating next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss the distribution(s) of your variable(s) of interest. Were there any unusual points? Did you need to perform any transformations?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Of the features you investigated, were there any unusual distributions? Did you perform any operations on the data to tidy, adjust, or change the form of the data? If so, why did you do this?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Exploration\n",
    "\n",
    "> In this section, investigate relationships between pairs of variables in your\n",
    "data. Make sure the variables that you cover here have been introduced in some\n",
    "fashion in the previous section (univariate exploration)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check distribution of 'state' relative to whether project has ended early:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference:\n",
    "# https://stackoverflow.com/questions/33271098/python-get-a-frequency-count-based-on-two-columns-variables-in-pandas-datafra\n",
    "df.groupby(['state','ended_early']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(data = df, x = 'state', hue = 'ended_early', palette = 'Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since each project 'state' only has projects that EITHER ended early or didn't, there is no distribution of endings to be illustrated within each 'state'. We have learned and confirmed that, not surprisingly, all projects which were 'cancelled' or 'suspended' ended early, and all project campaigns that 'failed' or were 'successful' in reaching their funding goal were open until the end of their deadline.\n",
    "\n",
    "#### Since I care about whether projects are successful or not, and 'live' project campaigns are still in progress and have yet to be cancelled or suspended, I will remove the project rows that have the state of 'live'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check distribution of 'is_starrable' relative to project 'state':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['state','is_starrable']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since 'is_starrable' is only true for projects that are 'live', and I am planning on excluding the 'live' projects, we can also remove the 'is_starrable' feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check distribution of success of projects split by 'main_cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notlive['successful'] = np.where(df_notlive.state == 'successful', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notlive[['name','state','successful']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15, 5])\n",
    "ax = sb.countplot(data = df_notlive, x = 'main_cat', hue = 'successful', order= df_notlive['main_cat'].value_counts().index);\n",
    "loc, labels = plt.xticks()\n",
    "ax.set_xticklabels(labels, rotation=45);\n",
    "\n",
    "# add annotations\n",
    "n_points = df_notlive['main_cat'].value_counts()\n",
    "i=0\n",
    "for p in ax.patches:\n",
    "    if i >= 15:\n",
    "        i = 0\n",
    "        height = p.get_height()\n",
    "        ax.text(p.get_x()+p.get_width()/2.,\n",
    "                height + 5,\n",
    "                '{:.2f}'.format(height/n_points[i]),\n",
    "                ha = 'center')\n",
    "        i += 1\n",
    "    else:\n",
    "        height = p.get_height()\n",
    "        ax.text(p.get_x()+p.get_width()/2.,\n",
    "                height + 5,\n",
    "                '{:.2f}'.format(height/n_points[i]),\n",
    "                ha = 'center')\n",
    "        i +=1\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk about some of the relationships you observed in this part of the investigation. How did the feature(s) of interest vary with other features in the dataset?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Did you observe any interesting relationships between the other features (not the main feature(s) of interest)?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Exploration\n",
    "\n",
    "> Create plots of three or more variables to investigate your data even\n",
    "further. Make sure that your investigations are justified, and follow from\n",
    "your work in the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk about some of the relationships you observed in this part of the investigation. Were there features that strengthened each other in terms of looking at your feature(s) of interest?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Were there any interesting or surprising interactions between features?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> At the end of your report, make sure that you export the notebook as an\n",
    "html file from the `File > Download as... > HTML` menu. Make sure you keep\n",
    "track of where the exported file goes, so you can put it in the same folder\n",
    "as this notebook for project submission. Also, make sure you remove all of\n",
    "the quote-formatted guide notes like this one before you finish your report!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
