{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Kickstarter Project Data\n",
    "## by Michael Mosin\n",
    "\n",
    "## Preliminary Wrangling\n",
    "\n",
    "This document explores a dataset comprised of various attributes for an assortment of 3786 Kickstarter projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages and set plots to be embedded inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "# Dataset downloaded from CSV link under \"2019-05-16\" on site: https://webrobots.io/kickstarter-datasets/\n",
    "df = pd.read_csv('Kickstarter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding ability to view all dataframe columns\n",
    "# as per https://stackoverflow.com/questions/49188960/how-to-show-all-of-columns-name-on-pandas-dataframe/49189503\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy of main dataframe so as to keep original data intact.\n",
    "df_copy = df.copy()\n",
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking Data Quality and Tidiness Issues:\n",
    "\n",
    "### Quality:\n",
    "\n",
    "- Variables \"created_at\", \"deadline\", \"launched_at\", and \"state_changed_at\" are set in unix time instead of readable datetime\n",
    "- Variables with financial values such as \"converted_pledged_amount\", \"goal\", \"pledged\", and \"usd_pledged\" are set to different decimal places, and should be rounded to at most two decimal places\n",
    "- Variables \"friends\", \"is_backing\", \"is_starred\", and \"permissions\" only have one entry and should be dropped\n",
    "- Only two entries are missing data for \"location\" (not a big deal, given that we have \"country\" data; these)\n",
    "- Only eleven entries are missing data for \"usd_type\" (this variable is not important to the investigation)\n",
    "\n",
    "### Tidiness:\n",
    "\n",
    "- Data entries in the columns \"category\", \"creator\", \"location\", \"photo\", \"profile\", and \"urls\" contain multiple pieces of information. If separated, they could be their own dataframes or made into additional columns in the main dataframe.\n",
    "    - The \"category\" variable can garner category and sub-category info for the projects\n",
    "    - The \"location\" variable can garner data regarding the project's state name, city name, and city type\n",
    "    - The \"creator\",\"photo\", \"profile\", \"urls\" variables have no data that is relevant to this project and should be dropped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Data Quality and Tidiness Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality: \n",
    "\n",
    "#### Remove (essentially) empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove variables that only have one entry.\n",
    "df_copy = df_copy.drop(columns = [\"friends\", \"is_backing\", \"is_starred\", \"permissions\"])\n",
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix time categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting unix time to readable date-time\n",
    "# as per https://stackoverflow.com/questions/19231871/convert-unix-time-to-readable-date-in-pandas-dataframe\n",
    "date_cols = [\"created_at\", \"deadline\", \"launched_at\", \"state_changed_at\"]\n",
    "for i in date_cols:\n",
    "    df_copy[i] = pd.to_datetime(df_copy[i],unit='s')\n",
    "\n",
    "df_copy[date_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[date_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix financial categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round financial values to at most two decimal places\n",
    "money_cols = [\"converted_pledged_amount\", \"goal\", \"pledged\", \"usd_pledged\"]\n",
    "for i in money_cols:\n",
    "    df_copy = df_copy.round(2)\n",
    "\n",
    "df_copy[money_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness: \n",
    "\n",
    "#### Feature Engineering - address tidiness issue of \"category\" variable by creating variables holding extracted values for main category and sub-category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View full string entry for \"category\" variable of fifth row entry to gauge the complexity of category strings:\n",
    "df_copy['category'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract product categories and sub-catgories from strings in \"category\" variable into their own columns in dataframe\n",
    "# (Used regular expression)\n",
    "\n",
    "import re  \n",
    "\n",
    "df_copy['main_cat'] = ''\n",
    "df_copy['sub_cat'] = ''\n",
    "\n",
    "for i in np.arange(df_copy.shape[0]):\n",
    "    match = re.findall('(([ &]|\\w+)+)', df_copy['category'][i])\n",
    "    df_copy['main_cat'][i] = match[5][0].title()\n",
    "    df_copy['sub_cat'][i] = match[6][0].title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[['name','main_cat', 'sub_cat', 'category']].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.main_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.sub_cat.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering - address tidiness issue of \"location\" variable by creating variables holding extracted values for state, city, and type of city:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[df_copy.location.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View full string entry for \"location\" variable of third row entry to gauge the complexity of location strings:\n",
    "df_copy['location'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract product (country) states, cities, and city types from strings in \"location\" variable into their own columns in dataframe\n",
    "# (Used regular expression)\n",
    "\n",
    "df_copy['location_state'] = ''\n",
    "df_copy['location_city'] = ''\n",
    "df_copy['location_type'] = ''\n",
    "\n",
    "for i in np.arange(df_copy.shape[0]):\n",
    "    if pd.notna(df_copy.location[i]) == True:\n",
    "        match = re.findall('((?:[^\"]\\w+)+)', df_copy['location'][i])\n",
    "        df_copy['location_state'][i] = match[17]\n",
    "        df_copy['location_city'][i] = match[3]\n",
    "        df_copy['location_type'][i] = match[19]\n",
    "    else:\n",
    "        df_copy['location_state'][i] = 'NaN'\n",
    "        df_copy['location_city'][i] = 'NaN'\n",
    "        df_copy['location_type'][i] = 'NaN'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[['name', 'country', 'location_state', 'location_city', 'location_type', 'location']][1930:1933]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the structure of your dataset?\n",
    "\n",
    "There are 3786 Kickstarter projects in this dataset, with a total of 37 features, some of which are untidy, and some of which are not of interest for my exploration. I have engineered a few categorical features (related to project ctegories and location) which may come to be useful for exploration. \n",
    "\n",
    "\n",
    "### What is/are the main feature(s) of interest in your dataset?\n",
    "\n",
    "I am interested in finding out which project qualities correlate with different types of project outcomes (or, the final \"state\" of the project). \n",
    "\n",
    "\n",
    "### What features in the dataset do you think will help support your investigation into your feature(s) of interest?\n",
    "\n",
    "I believe the following features could illuminate patterns in project outcomes:\n",
    "- Number of backers\n",
    "- Length of time project was open\n",
    "- Total money pledged (relative to funding goal)\n",
    "- Project category\n",
    "- Project location (country, city type)\n",
    "- If project had \"spotlight\"\n",
    "- If project was \"staff pick\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save wrangled dataframe to new CSV file to make future manipulating easier\n",
    "df_copy.to_csv('data_wrangled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlining Wrangled Dataset \n",
    "\n",
    "### Removing extra variables, and engineering other potentially relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages and set plots to be embedded inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import wrangled dataset\n",
    "df = pd.read_csv('data_wrangled.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary variables\n",
    "df.drop(columns = ['category',\n",
    "                   'converted_pledged_amount',\n",
    "                   'creator',\n",
    "                   'currency_symbol',\n",
    "                   'currency_trailing_code',\n",
    "                   'current_currency',\n",
    "                   'disable_communication',\n",
    "                   'fx_rate',\n",
    "                   'location',\n",
    "                   'photo',\n",
    "                   'profile',\n",
    "                   'slug',\n",
    "                   'source_url',\n",
    "                   'static_usd_rate',\n",
    "                   'urls',\n",
    "                   'usd_type'],\n",
    "       inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineering features related to the time variables:\n",
    "\n",
    "- created_at\n",
    "- launched_at\n",
    "- deadline\n",
    "- state_changed_at\n",
    "\n",
    "Reference:\n",
    "\n",
    "http://www.datasciencemadesimple.com/difference-two-timestamps-seconds-minutes-hours-pandas-python-2/\n",
    "https://docs.scipy.org/doc/numpy/reference/arrays.datetime.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that time variables are of 'datetime64' type:\n",
    "date_cols = [\"created_at\", \"deadline\", \"launched_at\", \"state_changed_at\"]\n",
    "for i in date_cols:\n",
    "    df[i] = pd.to_datetime(df[i])\n",
    "\n",
    "df[date_cols].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate length of time in days it took to launch project: 'time_to_launch'\n",
    "# (time between project creation and project launch: 'launched_at' - 'created_at')\n",
    "\n",
    "df['time_to_launch'] = df['launched_at'] - df['created_at']\n",
    "df['time_to_launch']=df['time_to_launch']/np.timedelta64(1,'D')\n",
    "df.time_to_launch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate length of time in days given for project to succeed: 'time_to_succeed'\n",
    "# (time between project launch and project deadline: 'deadline' - 'launched_at')\n",
    "\n",
    "df['time_to_succeed'] = df['deadline'] - df['launched_at']\n",
    "df['time_to_succeed']=df['time_to_succeed']/np.timedelta64(1,'D')\n",
    "df.time_to_succeed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate length of time in days project was active (or reached its final 'state') : 'time_active'\n",
    "# (time between project launch and project deadline: 'state_changed_at' - 'launched_at')\n",
    "\n",
    "df['time_active'] = df['state_changed_at'] - df['launched_at']\n",
    "df['time_active']=df['time_active']/np.timedelta64(1,'D')\n",
    "df.time_active.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm whether final 'state' occurred before or after 'deadline': 'ended_early'\n",
    "# Faster code instead of for loops as per reference:\n",
    "# https://stackoverflow.com/questions/27041724/using-conditional-to-generate-new-column-in-pandas-dataframe)\n",
    "\n",
    "df['ended_early'] = np.where(df.time_active < df.time_to_succeed, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['time_to_succeed','time_active','ended_early']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineering Feature: proportion of project funding relative to goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding ratio of confirmed funds relative to funding goals: 'funded_prop'\n",
    "# ('pledged' / 'goal')\n",
    "\n",
    "df['funded_prop'] = df['pledged'] / df['goal']\n",
    "df.funded_prop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Exploration\n",
    "\n",
    "> In this section, investigate distributions of individual variables. If\n",
    "you see unusual points or outliers, take a deeper look to clean things up\n",
    "and prepare yourself to look at relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set color for charts:\n",
    "base_color = sb.color_palette()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's the distribution of project campaign 'states'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(data = df, x = 'state', color = base_color);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's the proportion of campaigns that ended early?\n",
    "Plot 'ended_early' counts with proportion percentages over bars\n",
    "\n",
    "Reference: https://stackoverflow.com/questions/31749448/how-to-add-percentages-on-top-of-bars-in-seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the plot\n",
    "ax = sb.countplot(data = df, x = 'ended_early', color = base_color)\n",
    "\n",
    "# add annotations\n",
    "n_points = df.shape[0]\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 25,\n",
    "            '{:0.1f}%'.format(100*height/n_points),\n",
    "            ha = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I am insterested in comparing whether the different campaign 'states' have a split within them regarding whether they ended early or not. This will be explored with Bivariate Visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Make sure that, after every plot or related series of plots, that you\n",
    "include a Markdown cell with comments about what you observed, and what\n",
    "you plan on investigating next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss the distribution(s) of your variable(s) of interest. Were there any unusual points? Did you need to perform any transformations?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Of the features you investigated, were there any unusual distributions? Did you perform any operations on the data to tidy, adjust, or change the form of the data? If so, why did you do this?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Exploration\n",
    "\n",
    "> In this section, investigate relationships between pairs of variables in your\n",
    "data. Make sure the variables that you cover here have been introduced in some\n",
    "fashion in the previous section (univariate exploration)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check distribution of 'state' relative to whether project has ended early:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ended_early'].groupby(df['state']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(data = df, x = 'state', hue = 'ended_early', palette = 'Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since each project 'state' only has projects that EITHER ended early or didn't, there is no distribution to illustrate within each 'state'. We have learned and confirmed that, not surprisingly, all projects which were 'cancelled' or 'suspended' ended early, and all project campaigns that 'failed' or were 'successful' in reaching their funding goal were open until the end of their deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since I care about whether projects are successful or not, and 'live' project campaigns are still in progress and have yet to be cancelled or suspended, I will remove the project rows that have the state of 'live'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk about some of the relationships you observed in this part of the investigation. How did the feature(s) of interest vary with other features in the dataset?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Did you observe any interesting relationships between the other features (not the main feature(s) of interest)?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Exploration\n",
    "\n",
    "> Create plots of three or more variables to investigate your data even\n",
    "further. Make sure that your investigations are justified, and follow from\n",
    "your work in the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk about some of the relationships you observed in this part of the investigation. Were there features that strengthened each other in terms of looking at your feature(s) of interest?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Were there any interesting or surprising interactions between features?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> At the end of your report, make sure that you export the notebook as an\n",
    "html file from the `File > Download as... > HTML` menu. Make sure you keep\n",
    "track of where the exported file goes, so you can put it in the same folder\n",
    "as this notebook for project submission. Also, make sure you remove all of\n",
    "the quote-formatted guide notes like this one before you finish your report!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
